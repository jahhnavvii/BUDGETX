{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 135,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 0.11034528911113739,
      "learning_rate": 0.00019407407407407408,
      "loss": 2.7467678070068358,
      "step": 5
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.13790839910507202,
      "learning_rate": 0.0001866666666666667,
      "loss": 2.834311294555664,
      "step": 10
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.1696239560842514,
      "learning_rate": 0.00017925925925925927,
      "loss": 2.577989387512207,
      "step": 15
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.18587009608745575,
      "learning_rate": 0.00017185185185185185,
      "loss": 2.3721023559570313,
      "step": 20
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.2222013920545578,
      "learning_rate": 0.00016444444444444444,
      "loss": 2.4206724166870117,
      "step": 25
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.23922963440418243,
      "learning_rate": 0.00015703703703703705,
      "loss": 2.1584613800048826,
      "step": 30
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 0.3386520445346832,
      "learning_rate": 0.00014962962962962963,
      "loss": 2.1338666915893554,
      "step": 35
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.3258023262023926,
      "learning_rate": 0.00014222222222222224,
      "loss": 2.1440570831298826,
      "step": 40
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3322468101978302,
      "learning_rate": 0.00013481481481481482,
      "loss": 1.9818246841430665,
      "step": 45
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.3679398000240326,
      "learning_rate": 0.0001274074074074074,
      "loss": 1.7880340576171876,
      "step": 50
    },
    {
      "epoch": 1.2222222222222223,
      "grad_norm": 0.3521742820739746,
      "learning_rate": 0.00012,
      "loss": 1.7913379669189453,
      "step": 55
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.43210023641586304,
      "learning_rate": 0.0001125925925925926,
      "loss": 1.8046417236328125,
      "step": 60
    },
    {
      "epoch": 1.4444444444444444,
      "grad_norm": 0.44605904817581177,
      "learning_rate": 0.00010518518518518518,
      "loss": 1.7371334075927733,
      "step": 65
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 0.42477381229400635,
      "learning_rate": 9.777777777777778e-05,
      "loss": 1.7240703582763672,
      "step": 70
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.5465916395187378,
      "learning_rate": 9.037037037037038e-05,
      "loss": 1.5525290489196777,
      "step": 75
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 0.5596842765808105,
      "learning_rate": 8.296296296296296e-05,
      "loss": 1.509162998199463,
      "step": 80
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 0.3601875901222229,
      "learning_rate": 7.555555555555556e-05,
      "loss": 1.4747118949890137,
      "step": 85
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.4533637464046478,
      "learning_rate": 6.814814814814815e-05,
      "loss": 1.510048007965088,
      "step": 90
    },
    {
      "epoch": 2.111111111111111,
      "grad_norm": 0.7061386704444885,
      "learning_rate": 6.074074074074074e-05,
      "loss": 1.6299972534179688,
      "step": 95
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.5151873230934143,
      "learning_rate": 5.333333333333333e-05,
      "loss": 1.5779027938842773,
      "step": 100
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 0.46219390630722046,
      "learning_rate": 4.592592592592593e-05,
      "loss": 1.4385333061218262,
      "step": 105
    },
    {
      "epoch": 2.4444444444444446,
      "grad_norm": 0.3748422861099243,
      "learning_rate": 3.851851851851852e-05,
      "loss": 1.5290208816528321,
      "step": 110
    },
    {
      "epoch": 2.5555555555555554,
      "grad_norm": 0.40544936060905457,
      "learning_rate": 3.111111111111111e-05,
      "loss": 1.5491518020629882,
      "step": 115
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.43919506669044495,
      "learning_rate": 2.3703703703703707e-05,
      "loss": 1.5282217025756837,
      "step": 120
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.37024474143981934,
      "learning_rate": 1.62962962962963e-05,
      "loss": 1.4333892822265626,
      "step": 125
    },
    {
      "epoch": 2.888888888888889,
      "grad_norm": 0.3708740472793579,
      "learning_rate": 8.88888888888889e-06,
      "loss": 1.4826298713684083,
      "step": 130
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.47391629219055176,
      "learning_rate": 1.4814814814814817e-06,
      "loss": 1.4273173332214355,
      "step": 135
    }
  ],
  "logging_steps": 5,
  "max_steps": 135,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1644618621911040.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
